{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce0fa1d",
   "metadata": {},
   "source": [
    "# CNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aef3ceec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 17:44:34.976479: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_openml\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[0;32m~/miniconda3/envs/fma/lib/python3.10/site-packages/tensorflow/__init__.py:470\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_current_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    469\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m     \u001b[43m_keras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fma/lib/python3.10/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fma/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fma/lib/python3.10/site-packages/keras/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m~/miniconda3/envs/fma/lib/python3.10/site-packages/keras/models/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[0;32m~/miniconda3/envs/fma/lib/python3.10/site-packages/keras/engine/functional.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n",
      "File \u001b[0;32m~/miniconda3/envs/fma/lib/python3.10/site-packages/tensorflow/_api/v2/compat/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatible\n",
      "File \u001b[0;32m~/miniconda3/envs/fma/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v2/__init__.py:51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mlir\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m profiler\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization\n",
      "File \u001b[0;32m~/miniconda3/envs/fma/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v2/nn/__init__.py:158\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Primitive Neural Net (NN) Operations.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m## Notes on padding\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn_cell_wrapper_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeviceWrapper \u001b[38;5;28;01mas\u001b[39;00m RNNCellDeviceWrapper\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn_cell_wrapper_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DropoutWrapper \u001b[38;5;28;01mas\u001b[39;00m RNNCellDropoutWrapper\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#os.chdir(\"/drive/MyDrive/data\")\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, RandomAffine, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import random\n",
    "import utils\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c26c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveheavy(df, name, n):  #functions to save havy dataframes in multiple files\n",
    "    l= len(df)\n",
    "    for i in range(n-1):\n",
    "        df.iloc[int((l/n)*i):int((l/n)*(i+1))].to_hdf(f'{name}_{i+1}.h5', 'x', mode='w')\n",
    "    df.iloc[int((l/n)*(n-1)):l].to_hdf(f'{name}_{n}.h5', 'x', mode='w')\n",
    "    \n",
    "def readheavy(name, n, column, Dir):\n",
    "    result = pd.DataFrame(columns=column)\n",
    "    for i in range(n):\n",
    "        #df = pd.read_hdf(f'Data/{Dir}/{name}_{i+1}.h5', 'x')\n",
    "        df = pd.read_hdf(f\"{name}_{i+1}.h5\", 'x')\n",
    "        result = pd.concat([result, df], ignore_index=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbfa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restore Datasets\n",
    "\n",
    "test = readheavy('test', 1, ['audio', 'y'], 'Audio')\n",
    "##validation = readheavy('validation', 2, ['audio', 'y'], 'Audio')\n",
    "#training = readheavy('training', 16, ['audio', 'y'], 'Audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8158f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stft(data):\n",
    "    df = pd.DataFrame(columns=['stft', 'y'])\n",
    "    for j in range(len(data)):\n",
    "        audio = data.loc[j, 'audio']\n",
    "        stft = np.abs(librosa.stft(audio, n_fft=1024, hop_length=512))\n",
    "        y = data.loc[j, 'y']\n",
    "        new_row = pd.DataFrame({'stft':[stft], 'y':[y]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def get_mel(data):\n",
    "    df = pd.DataFrame(columns=['mel', 'y'])\n",
    "    for j in range(len(data)):\n",
    "        audio = data.loc[j, 'audio']\n",
    "        mel = np.abs(librosa.stft(audio, n_fft=1024, hop_length=512))\n",
    "        y = data.loc[j, 'y']\n",
    "        new_row = pd.DataFrame({'mel':[mel], 'y':[y]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I convert Audio into stft data\n",
    "\n",
    "\n",
    "test = get_stft(test[:10])\n",
    "#validation = get_stft(validation)\n",
    "#training = get_stft(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff50ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_stft(df, n_samples):\n",
    "    df_clip = pd.DataFrame(columns=list(df.columns))\n",
    "    t = len(df[df.columns[0]][1][1])\n",
    "    for j in range(len(df)):\n",
    "        full = df.loc[j, df.columns[0]].transpose()\n",
    "        n=0\n",
    "        while (n<(len(full)-n_samples)):\n",
    "            clip = full[n: (n+n_samples)]\n",
    "            y = df.loc[j, 'y']\n",
    "            new_row = pd.DataFrame({df.columns[0]:[clip], 'y':[y]})\n",
    "            df_clip = pd.concat([df_clip, new_row], ignore_index=True)\n",
    "            n+=int(n_samples/2)\n",
    "    return df_clip\n",
    "\n",
    "def clip_audio(df, n_samples):\n",
    "    df_clip = pd.DataFrame(columns=list(df.columns))\n",
    "    t = len(df[df.columns[0]][1])\n",
    "    for j in range(len(df)):\n",
    "        full = df.loc[j, df.columns[0]]\n",
    "        n=0\n",
    "        while (n<(len(full)-n_samples)):\n",
    "            clip = full[n: (n+n_samples)]\n",
    "            y = df.loc[j, 'y']\n",
    "            new_row = pd.DataFrame({df.columns[0]:[clip], 'y':[y]})\n",
    "            df_clip = pd.concat([df_clip, new_row], ignore_index=True)\n",
    "            n+=int(n_samples/2)\n",
    "    return df_clip\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clip = clip_stft(test, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diego = pd.DataFrame(test_clip).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diego.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7d59e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m diego \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiego.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m,allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "diego = np.load(\"diego.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff438f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diego.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc0241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Class for the creation of torch manageble datasets, with Format one can select the desired input column \n",
    "class DataDiego(Dataset):\n",
    "\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.x = data[:,0]\n",
    "        self.y = data[:,1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "       \n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            #x = x.unsqueeze(0)\n",
    "            \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6997f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    ToTensor(), #this converts numpy or Pil image to torch tensor and normalizes it in 0, 1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76641069",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DataDiego(data=diego,transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of dataloader classes\n",
    "batch_size = 64\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ae6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in test_dataloader:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7239eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to add dropout layers \n",
    "\n",
    "class NNET1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NNET1, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=128,kernel_size=(4,513)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,1)),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(4,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,1)),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(4,1)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Input of fc1 is 256\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        max_pool = F.max_pool2d(x, kernel_size=(26,1))\n",
    "        avg_pool = F.avg_pool2d(x, kernel_size=(26,1))\n",
    "        x = max_pool + avg_pool\n",
    "        x = self.fc(x.view(-1, 256))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbe510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNET2(nn.Module):\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(NNET2, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=256,kernel_size=(4,513)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.c2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(4, 1),padding=(2,0)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.c3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(4, 1),padding=(1,0)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        c1 = self.c1(x)\n",
    "        c2 = self.c2(c1)\n",
    "        c3 = self.c3(c2)\n",
    "        x = c1 + c3\n",
    "        max_pool = F.max_pool2d(x, kernel_size=(125,1))\n",
    "        avg_pool = F.avg_pool2d(x, kernel_size=(125,1))\n",
    "        x = max_pool + avg_pool\n",
    "        x = self.fc(x.view(-1, 256))\n",
    "        return x \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e98891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake spectrogram 128x513\n",
    "x = torch.randn(1, 1, 128, 513)\n",
    "\n",
    "# Create model\n",
    "model = NNET2()\n",
    "\n",
    "\n",
    "# Forward pass\n",
    "output = model(x)\n",
    "\n",
    "# Print output shape\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader.dataset.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73933136",
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = test_dataloader.dataset.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ece16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = torch.Tensor(prova[0]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Adam, Adadelta\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "# Create model\n",
    "model = NNET2()\n",
    "opt = Adadelta(model.parameters())\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "epochs=10\n",
    "best_val = np.inf\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    iterator = tqdm(test_dataloader)\n",
    "    for batch_x, batch_y in iterator:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        y_pred = model(batch_x)\n",
    "\n",
    "        loss = loss_fn(y_pred, batch_y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        iterator.set_description(f\"Train loss: {loss.detach().cpu().numpy()}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        true = []\n",
    "        for batch_x, batch_y in tqdm(test_dataloader):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            y_pred = model(batch_x)\n",
    "\n",
    "            predictions.append(y_pred)\n",
    "            true.append(batch_y)\n",
    "        predictions = torch.cat(predictions, axis=0)\n",
    "        true = torch.cat(true, axis=0)\n",
    "        val_loss = loss_fn(predictions, true)\n",
    "        val_acc = (torch.sigmoid(predictions).round() == true).float().mean()\n",
    "        print(f\"loss: {val_loss}, accuracy: {val_acc}\")\n",
    "    \n",
    "    if val_loss < best_val:\n",
    "        print(\"Saved Model\")\n",
    "        torch.save(model.state_dict(), \"model.pt\")\n",
    "        best_val = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080e6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_curve, roc_auc_score\n",
    "\n",
    "def evaluate_network(dataloader, model, data_split):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        true = []\n",
    "        for batch_x, batch_y in tqdm(dataloader):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            y_pred = model(batch_x)\n",
    "\n",
    "            predictions.append(y_pred)\n",
    "            true.append(batch_y)\n",
    "        predictions = torch.cat(predictions, axis=0)\n",
    "        true = torch.cat(true, axis=0)\n",
    "        loss = loss_fn(predictions, true).detach().cpu().numpy()\n",
    "        predictions = torch.sigmoid(predictions).detach().cpu().numpy()\n",
    "        true = true.detach().cpu().numpy()\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(true, predictions)\n",
    "        auc = roc_auc_score(true, predictions)\n",
    "        predictions = predictions.round()\n",
    "        precision, recall, fscore, _= precision_recall_fscore_support(true, predictions, average='binary')\n",
    "        accuracy = accuracy_score(true, predictions)\n",
    "\n",
    "        print(f\"{data_split} loss: {loss}, accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1: {fscore}, roc_auc: {auc}\")\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'{data_split} receiver operating characteristic (ROC)')\n",
    "        plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e661c8e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NNET2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNNET2\u001b[49m()\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m evaluate_network(test_dataloader, model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NNET2' is not defined"
     ]
    }
   ],
   "source": [
    "model = NNET2()\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "\n",
    "evaluate_network(test_dataloader, model, \"Test Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c838949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
