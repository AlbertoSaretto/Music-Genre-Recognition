{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd # this module is useful to work with tabular data\n",
    "import random # this module will be used to select random samples from a collection\n",
    "import os # this module will be used just to create directories in the local filesystem\n",
    "from tqdm import tqdm # this module is useful to plot progress bars\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import h5py\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = h5py.File('h5Dataset/train_x.h5', 'r')[\"train\"][:]\n",
    "y_train = h5py.File('h5Dataset/train_y.h5', 'r')[\"train\"][:]\n",
    "\n",
    "x_valid = h5py.File('h5Dataset/valid_x.h5', 'r')[\"valid\"][:]\n",
    "y_valid = h5py.File('h5Dataset/valid_y.h5', 'r')[\"valid\"][:]\n",
    "\n",
    "x_test = h5py.File('h5Dataset/test_x.h5', 'r')[\"test\"][:]\n",
    "y_test = h5py.File('h5Dataset/test_y.h5', 'r')[\"test\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAudioH5_colab(Dataset):\n",
    "\n",
    "    def __init__(self,data_x,data_y,transform=None,input_type=\"2D\"):\n",
    "        \n",
    "        self.x = data_x\n",
    "        self.y = data_y\n",
    "        self.transform = transform\n",
    "        #Select type of input: 2D or 1D\n",
    "        self.type = input_type\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.x)\n",
    "\n",
    "    def create_input(self, audio,sr=22050):\n",
    "\n",
    "        \"\"\"\n",
    "        This function takes an audio clip and creates the input for the model\n",
    "        \"\"\"\n",
    "      \n",
    "        # Get audio\n",
    "\n",
    "        # load audio track\n",
    "        #with warnings.catch_warnings():\n",
    "        #    warnings.simplefilter('ignore')\n",
    "        \"\"\"\n",
    "        #Select random clip from audio\n",
    "        start = np.random.randint(0, (audio.shape[0]-2**18))\n",
    "        audio = audio[start:start+2**18]\n",
    "        \"\"\"\n",
    "\n",
    "        if self.type ==  \"2D\":\n",
    "            \n",
    "            #Get 2D spectrogram\n",
    "            stft = np.abs(librosa.stft(audio, n_fft=4096, hop_length=2048))\n",
    "            \n",
    "            mel = librosa.feature.melspectrogram(sr=sr, S=stft**2, n_mels=513)[:,:128]\n",
    "            mel = librosa.power_to_db(mel).T\n",
    "            return mel[np.newaxis,:] #Add channel dimension\n",
    "    \n",
    "        return audio[np.newaxis,:] #Add channel dimension\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # get input and label\n",
    "\n",
    "        x = self.x[idx]\n",
    "        x = self.create_input(x)\n",
    "\n",
    "        y = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "           \n",
    "        return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(x):\n",
    "    Xmin = torch.min(x)\n",
    "    Xmax = torch.max(x)\n",
    "    return (x-Xmin)/(Xmax-Xmin)\n",
    "\n",
    "# Standard transformations for images\n",
    "# Mean and std are computed on one file of the training set\n",
    "transforms = v2.Compose([v2.ToTensor(),\n",
    "    v2.RandomResizedCrop(size=(128,513), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    # v2.Normalize(mean=[1.0784853], std=[4.0071154]),\n",
    "    v2.Lambda(lambda x: MinMaxScaler(x))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataAudioH5_colab(x_train,y_train,input_type=\"2D\")\n",
    "valid_dataset = DataAudioH5_colab(x_valid,y_valid,input_type=\"2D\")\n",
    "test_dataset  = DataAudioH5_colab(x_test,y_test,input_type=\"2D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader  = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=os.cpu_count())\n",
    "valid_dataloader  = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=os.cpu_count())\n",
    "test_dataloader   = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNET2(nn.Module):\n",
    "\n",
    "    def __init__(self,initialisation=\"xavier\"):\n",
    "        super(NNET2, self).__init__()\n",
    "\n",
    "\n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=256,kernel_size=(4,513)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(.2)\n",
    "        )\n",
    "\n",
    "        self.c2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(4, 1),padding=(2,0)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(.2)\n",
    "        )\n",
    "\n",
    "        self.c3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(4, 1),padding=(1,0)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(.2)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(300, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(150, 8),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Mi chiedo cosa succede se voglio caricare i miei parametri. Necessario debugging esplicito\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        c1 = self.c1(x)\n",
    "        c2 = self.c2(c1)\n",
    "        c3 = self.c3(c2)\n",
    "        x = c1 + c3\n",
    "        max_pool = F.max_pool2d(x, kernel_size=(125,1))\n",
    "        avg_pool = F.avg_pool2d(x, kernel_size=(125,1))\n",
    "        x = torch.cat([max_pool,avg_pool],dim=1)\n",
    "        x = self.fc(x.view(x.size(0), -1)) # maybe I should use flatten instead of view\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "model = NNET2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "### Define the loss function\n",
    "loss_fn = CrossEntropyLoss()\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr = 1e-3\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_epoch(model, device, dataloader, loss_fn, optimizer):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    model.train()\n",
    "    losses = []\n",
    "        \n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for x_batch, label_batch in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "       \n",
    "        x_batch = x_batch.to(device)\n",
    "        label_batch = label_batch.to(device)\n",
    "\n",
    "        out = model(x_batch)\n",
    "        loss = loss_fn(out, label_batch) \n",
    "            \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    losses = np.mean(losses)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, device, dataloader, loss_fn):\n",
    "    # Set eval mode for both the encoder and the decoder\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for x_batch, label_batch in (dataloader): \n",
    "       \n",
    "        x_batch = x_batch.to(device)\n",
    "        label_batch = label_batch.to(device)\n",
    "\n",
    "        out = model(x_batch)\n",
    "\n",
    "        conc_out.append(out)\n",
    "        conc_label.append(label_batch)\n",
    "    # Create a single tensor with all the values in the lists\n",
    "    conc_out = torch.cat(conc_out)\n",
    "    conc_label = torch.cat(conc_label) \n",
    "    # Evaluate global loss\n",
    "    val_loss = loss_fn(conc_out, conc_label)\n",
    "    # Evaluate accuracy\n",
    "    val_acc = np.sum(np.argmax(conc_label.detach().cpu().numpy(), axis=1) == np.argmax(conc_out.detach().cpu().numpy(), axis=1)) / len(conc_out)\n",
    "    \n",
    "    return val_loss.detach().cpu().numpy(), val_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training cycle\n",
    "num_epochs = 1\n",
    "train_losses = []\n",
    "val_losses   = []\n",
    "val_accs     = []\n",
    "\n",
    "for epoch in (range(num_epochs)):\n",
    "    \n",
    "    \n",
    "    ### Training (use the training function)\n",
    "    train_loss = train_epoch(\n",
    "        model=model, \n",
    "        device=device, \n",
    "        dataloader=train_dataloader, \n",
    "        loss_fn=loss_fn, \n",
    "        optimizer=optim)\n",
    "    print(f'TRAIN - EPOCH {epoch+1}/{num_epochs} - loss: {train_loss}')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_epoch(\n",
    "        model=model, \n",
    "        device=device, \n",
    "        dataloader=valid_dataloader, \n",
    "        loss_fn=loss_fn)\n",
    "    val_losses.append(val_loss[0])\n",
    "    val_accs.append(val_loss[1])\n",
    "    # Print Validationloss\n",
    "    print(f\"VALIDATION - EPOCH {epoch+1}/{num_epochs} - loss:\", val_loss[0].item(), \"\\n\")\n",
    "\n",
    "    \n",
    "    # Save network parameters\n",
    "    torch.save(model.state_dict(), 'nnet2D.pth')\n",
    "    # NOTE: Remember to save also the parameters of the optimizer if you want to restore and continue the training\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
