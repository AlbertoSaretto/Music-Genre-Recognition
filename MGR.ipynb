{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce0fa1d",
   "metadata": {},
   "source": [
    "# CNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef3ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#os.chdir(\"/drive/MyDrive/data\")\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, RandomAffine, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import random\n",
    "import utils\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 5)\n",
    "\n",
    "sr = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c26c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveheavy(a, name, n):  #functions to save havy dataframes in multiple files\n",
    "    l= len(a)\n",
    "    if(n>1):\n",
    "        for i in range(n-1):\n",
    "            a_i = a[int((l/n)*i):int((l/n)*(i+1))]\n",
    "            np.save(f'{name}_{i+1}.npy', a_i)\n",
    "    a_i = a[int((l/n)*(n-1)):l]\n",
    "    np.save(f'{name}_{n}.npy', a_i)\n",
    "    \n",
    "def readheavy(name, n, Dir):\n",
    "    a = np.array([0,0])\n",
    "    for i in range(n):\n",
    "        new_a = np.load(f'Data/{Dir}/{name}_{i+1}.npy', allow_pickle = True)\n",
    "        a = np.vstack([a, new_a])\n",
    "    return a[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfbfa80",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m test \u001b[38;5;241m=\u001b[39m readheavy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAudio\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m training \u001b[38;5;241m=\u001b[39m readheavy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAudio\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m validation \u001b[38;5;241m=\u001b[39m \u001b[43mreadheavy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAudio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m, in \u001b[0;36mreadheavy\u001b[1;34m(name, n, Dir)\u001b[0m\n\u001b[0;32m     11\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m---> 13\u001b[0m     new_a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([a, new_a])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\alber\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32mc:\\Users\\alber\\anaconda3\\lib\\site-packages\\numpy\\lib\\format.py:781\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    779\u001b[0m     pickle_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 781\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# Friendlier error message\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnpickling a python object failed: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    785\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou may need to pass the encoding= option \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    786\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto numpy.load\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (err,)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Restore Datasets\n",
    "\n",
    "test = readheavy('test', 2, 'Audio')\n",
    "training = readheavy('training', 16, 'Audio')\n",
    "validation = readheavy('validation', 2, 'Audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3705e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6394, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8158f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stft(a):\n",
    "    for j in range(len(a)):\n",
    "        audio = a[j, 0]\n",
    "        stft = np.abs(librosa.stft(audio, n_fft=1024, hop_length=512))\n",
    "        a[j ,0] = stft\n",
    "    return a\n",
    "\n",
    "def get_mel(a):\n",
    "    for j in range(len(a)):\n",
    "        audio = a[j,0]\n",
    "        stft = np.abs(librosa.stft(audio, n_fft=1024, hop_length=512))\n",
    "        mel = mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n",
    "        a[j,0] = mel\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75a2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I convert Audio into stft data\n",
    "\n",
    "test = get_stft(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bdb02f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = get_stft(validation)\n",
    "training = get_stft(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdff50ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_stft(a, n_samples):\n",
    "    a_clip = np.array([0,0])\n",
    "    for j in range(len(a)):\n",
    "        full = a[j, 0].T\n",
    "        n=0\n",
    "        while (n<(len(full)-n_samples)):\n",
    "            clip = full[n: (n+n_samples)]\n",
    "            y = a[j, 1]\n",
    "            new_row = np.array([clip, y], dtype=object)\n",
    "            a_clip = np.vstack([a_clip, new_row])\n",
    "            n+=int(n_samples/2)\n",
    "    return a_clip[1:]\n",
    "\n",
    "\n",
    "def clip_audio(df, n_samples):\n",
    "    a_clip = np.array([0,0])\n",
    "    for j in range(len(a)):\n",
    "        full = df[j, 0]\n",
    "        n=0\n",
    "        while (n<(len(full)-n_samples)):\n",
    "            clip = full[n: (n+n_samples)]\n",
    "            y = df[j, 1]\n",
    "            new_row = np.array([clip, y], dtype=object)\n",
    "            a_clip = np.vstack([a_clip, new_row])\n",
    "            n+=int(n_samples/2)\n",
    "    return a_clip[1:]\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5734007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = clip_stft(test, 128)\n",
    "validation = clip_stft(validation, 128)\n",
    "training = clip_stft(training, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "912134f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 513)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0454bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Class for the creation of torch manageble datasets, with Format one can select the desired input column \n",
    "class DataAudio(Dataset):\n",
    "\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.x = data[:,0]\n",
    "        self.y = data[:,1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "       \n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            #x = x.unsqueeze(0)\n",
    "            \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c6997f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    ToTensor(), #this converts numpy or Pil image to torch tensor and normalizes it in 0, 1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76641069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of torch suited dataset classes  (change string 'mel' to select desired Format)\n",
    "test_dataset = DataAudio(data=test, transform=transforms)\n",
    "validation_dataset = DataAudio(data=validation, transform=transforms)\n",
    "training_dataset = DataAudio(data=training, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c857d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_dataset\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad5d3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of dataloader classes\n",
    "batch_size = 64\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "training_dataloader = DataLoader(training_dataset, batch_size, shuffle=True, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc4b56a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[2.1080021e-04, 2.0972929e-04, 2.0654705e-04, ..., 8.1103675e-09,\n",
       "               8.0495903e-09, 8.0293825e-09],\n",
       "              [3.8682382e+00, 5.6146770e+00, 1.0434763e+01, ..., 3.2188848e-07,\n",
       "               7.4267308e-07, 3.5079273e-07],\n",
       "              [1.7605966e+00, 4.1246676e+00, 6.5461721e+00, ..., 1.7453565e-06,\n",
       "               4.9375876e-07, 1.2367860e-07],\n",
       "              ...,\n",
       "              [2.2091374e+00, 1.3930146e+00, 1.0820771e+01, ..., 1.9613076e-06,\n",
       "               2.2745394e-06, 6.6840818e-07],\n",
       "              [3.5874403e+00, 5.3710556e+00, 1.9456934e+01, ..., 3.6745055e-07,\n",
       "               1.0445683e-06, 1.6783180e-06],\n",
       "              [2.8450794e+00, 5.4273024e+00, 2.3327595e+01, ..., 8.4913364e-07,\n",
       "               9.5739790e-07, 2.4902607e-07]], dtype=float32)                  ,\n",
       "       array([[2.1542284e+00, 3.2158666e+00, 2.2255291e+01, ..., 9.5538928e-07,\n",
       "               3.7759537e-07, 1.0313137e-06],\n",
       "              [1.1447760e+00, 9.4032307e+00, 3.8288792e+01, ..., 1.1260280e-06,\n",
       "               8.5929702e-07, 1.2015973e-07],\n",
       "              [3.3577003e+00, 4.4295855e+00, 1.7593153e+01, ..., 2.4880426e-06,\n",
       "               6.2478335e-07, 5.4908094e-07],\n",
       "              ...,\n",
       "              [1.6546746e-01, 6.5152583e+00, 1.0483542e+01, ..., 5.4561770e-07,\n",
       "               2.4837277e-06, 1.6743388e-06],\n",
       "              [2.0687787e-01, 8.3464546e+00, 2.4485813e+01, ..., 1.5829823e-06,\n",
       "               1.6148014e-06, 3.3330369e-07],\n",
       "              [1.7050300e+00, 7.7845316e+00, 1.0339426e+01, ..., 2.1591989e-06,\n",
       "               1.4442126e-06, 2.6432909e-07]], dtype=float32)                  ,\n",
       "       array([[1.5419899e+00, 8.7817202e+00, 2.5200851e+01, ..., 1.6352147e-06,\n",
       "               1.3922287e-06, 2.5313939e-06],\n",
       "              [3.3874767e+00, 4.4367828e+00, 4.1645557e+01, ..., 1.3211247e-06,\n",
       "               4.2064357e-06, 4.0799900e-06],\n",
       "              [2.7743316e+00, 3.5164890e+01, 1.0674195e+02, ..., 3.1536244e-06,\n",
       "               2.6553141e-06, 1.8013200e-06],\n",
       "              ...,\n",
       "              [1.8436420e+00, 8.4688568e+00, 2.2305140e+01, ..., 8.8558215e-07,\n",
       "               2.3068610e-06, 2.8792060e-06],\n",
       "              [1.1279185e+00, 6.1889544e+00, 1.6218510e+01, ..., 2.6719870e-06,\n",
       "               2.1317596e-06, 3.1886893e-06],\n",
       "              [1.5746701e+00, 1.8778969e+00, 1.0934070e+01, ..., 3.8892631e-07,\n",
       "               7.1925564e-07, 6.2429257e-07]], dtype=float32)                  ,\n",
       "       ...,\n",
       "       array([[5.2242190e-01, 3.2732544e+00, 1.0928258e+01, ..., 6.1749199e-07,\n",
       "               1.2240343e-06, 2.4688695e-06],\n",
       "              [1.2271920e-03, 1.7763313e+00, 4.3251433e+00, ..., 4.4050089e-06,\n",
       "               1.0202997e-06, 1.4214155e-06],\n",
       "              [2.2973366e-01, 9.2147452e-01, 1.9209405e+00, ..., 1.5454176e-06,\n",
       "               2.0470561e-06, 1.8924233e-06],\n",
       "              ...,\n",
       "              [3.8557160e-03, 7.3448061e-03, 1.7982950e-02, ..., 1.6537710e-07,\n",
       "               9.3203091e-08, 8.1567272e-08],\n",
       "              [2.2912486e-03, 3.9325980e-03, 1.0870035e-02, ..., 3.0729669e-07,\n",
       "               1.6954272e-07, 1.0095230e-07],\n",
       "              [1.8738991e-03, 8.5427258e-03, 2.8405717e-02, ..., 9.6857498e-08,\n",
       "               1.0849355e-07, 1.3266840e-07]], dtype=float32)                  ,\n",
       "       array([[1.7021427e-02, 2.6377852e+00, 3.7573576e+00, ..., 9.7033490e-06,\n",
       "               4.7383387e-06, 3.3381039e-06],\n",
       "              [6.1962390e-01, 1.5325407e+00, 1.6875462e+01, ..., 4.1345479e-06,\n",
       "               1.3708841e-05, 1.3176932e-05],\n",
       "              [3.8561422e-01, 3.9351404e+00, 1.4963678e+01, ..., 1.3814196e-06,\n",
       "               7.2513797e-07, 1.0445597e-07],\n",
       "              ...,\n",
       "              [7.7471654e-03, 2.6765652e-02, 9.4658688e-02, ..., 2.1102744e-07,\n",
       "               3.9194805e-07, 1.4416622e-07],\n",
       "              [9.8087573e-03, 1.0935025e-02, 9.1317937e-02, ..., 1.8296613e-07,\n",
       "               2.4523567e-07, 2.4224215e-07],\n",
       "              [1.1918112e-02, 3.1025156e-02, 5.3606998e-02, ..., 1.3482170e-07,\n",
       "               1.3324701e-07, 2.0783642e-07]], dtype=float32)                  ,\n",
       "       array([[3.79031349e-04, 9.77638457e-03, 1.72140077e-02, ...,\n",
       "               1.77465736e-07, 7.92055772e-08, 2.75111276e-08],\n",
       "              [2.75563523e-02, 3.00899092e-02, 7.03807035e-03, ...,\n",
       "               5.38671338e-06, 6.02913906e-06, 7.76045727e-06],\n",
       "              [4.16338593e-01, 3.37099940e-01, 1.83449388e-01, ...,\n",
       "               1.96537185e-05, 6.76584386e-06, 7.21664128e-06],\n",
       "              ...,\n",
       "              [2.75537558e-02, 2.40513012e-02, 2.12215539e-02, ...,\n",
       "               5.16371472e-07, 1.27056481e-07, 7.14787447e-08],\n",
       "              [1.12040062e-03, 1.47595908e-02, 2.33213343e-02, ...,\n",
       "               1.65748716e-07, 1.13206575e-07, 5.14526910e-08],\n",
       "              [6.68914057e-03, 7.82532059e-03, 4.58210632e-02, ...,\n",
       "               7.02868590e-08, 3.76574967e-08, 1.03904760e-07]], dtype=float32)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader.dataset.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c00df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_x, batch_y in test_dataloader:\n",
    "        print(batch_x)\n",
    "        print(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e00f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to add dropout layers \n",
    "\n",
    "class NNET1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NNET1, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=128,kernel_size=(4,513)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,1)),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(4,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,1)),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(4,1)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Input of fc1 is 256\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        max_pool = F.max_pool2d(x, kernel_size=(26,1))\n",
    "        avg_pool = F.avg_pool2d(x, kernel_size=(26,1))\n",
    "        x = max_pool + avg_pool\n",
    "        x = self.fc(x.view(-1, 256))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dcbe510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remember to add dropout\n",
    "\n",
    "class NNET2(nn.Module):\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(NNET2, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=256,kernel_size=(4,513)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.c2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(4, 1),padding=(2,0)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.c3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(4, 1),padding=(1,0)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        c1 = self.c1(x)\n",
    "        c2 = self.c2(c1)\n",
    "        c3 = self.c3(c2)\n",
    "        x = c1 + c3\n",
    "        max_pool = F.max_pool2d(x, kernel_size=(125,1))\n",
    "        avg_pool = F.avg_pool2d(x, kernel_size=(125,1))\n",
    "        x = max_pool + avg_pool\n",
    "        x = self.fc(x.view(-1, 256))\n",
    "        return x \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64e98891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# Fake spectrogram 128x513\n",
    "x = torch.randn(1, 1, 128, 513)\n",
    "\n",
    "# Create model\n",
    "model = NNET2()\n",
    "\n",
    "\n",
    "# Forward pass\n",
    "output = model(x)\n",
    "\n",
    "# Print output shape\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "691023c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/238 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD, Adam, Adadelta\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "# Create model\n",
    "model = NNET2()\n",
    "opt = Adadelta(model.parameters())\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "epochs=10\n",
    "best_val = np.inf\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    iterator = tqdm(test_dataloader)\n",
    "    for batch_x, batch_y in iterator:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        y_pred = model(batch_x)\n",
    "\n",
    "        loss = loss_fn(y_pred, batch_y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        iterator.set_description(f\"Train loss: {loss.detach().cpu().numpy()}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        true = []\n",
    "        for batch_x, batch_y in tqdm(test_dataloader):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            y_pred = model(batch_x)\n",
    "\n",
    "            predictions.append(y_pred)\n",
    "            true.append(batch_y)\n",
    "        predictions = torch.cat(predictions, axis=0)\n",
    "        true = torch.cat(true, axis=0)\n",
    "        val_loss = loss_fn(predictions, true)\n",
    "        val_acc = (torch.sigmoid(predictions).round() == true).float().mean()\n",
    "        print(f\"loss: {val_loss}, accuracy: {val_acc}\")\n",
    "    \n",
    "    if val_loss < best_val:\n",
    "        print(\"Saved Model\")\n",
    "        torch.save(model.state_dict(), \"model.pt\")\n",
    "        best_val = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803aee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_curve, roc_auc_score\n",
    "\n",
    "def evaluate_network(dataloader, model, data_split):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        true = []\n",
    "        for batch_x, batch_y in tqdm(dataloader):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            y_pred = model(batch_x)\n",
    "\n",
    "            predictions.append(y_pred)\n",
    "            true.append(batch_y)\n",
    "        predictions = torch.cat(predictions, axis=0)\n",
    "        true = torch.cat(true, axis=0)\n",
    "        loss = loss_fn(predictions, true).detach().cpu().numpy()\n",
    "        predictions = torch.sigmoid(predictions).detach().cpu().numpy()\n",
    "        true = true.detach().cpu().numpy()\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(true, predictions)\n",
    "        auc = roc_auc_score(true, predictions)\n",
    "        predictions = predictions.round()\n",
    "        precision, recall, fscore, _= precision_recall_fscore_support(true, predictions, average='binary')\n",
    "        accuracy = accuracy_score(true, predictions)\n",
    "\n",
    "        print(f\"{data_split} loss: {loss}, accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1: {fscore}, roc_auc: {auc}\")\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'{data_split} receiver operating characteristic (ROC)')\n",
    "        plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabdc92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNET2()\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "\n",
    "evaluate_network(test_dataloader, model, \"Test Dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
