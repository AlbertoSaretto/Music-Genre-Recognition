{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce0fa1d",
   "metadata": {},
   "source": [
    "# CNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef3ceec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\alber\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Impossibile trovare la procedura specificata'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#os.chdir(\"/drive/MyDrive/data\")\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, RandomAffine, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter\n",
    "import torch\n",
    "\n",
    "import random\n",
    "import utils\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130d6b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "\n",
    "# Disable all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c26c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveheavy(df, name, n):  #functions to save havy dataframes in multiple files\n",
    "    l= len(df)\n",
    "    for i in range(n-1):\n",
    "        df.iloc[int((l/n)*i):int((l/n)*(i+1))].to_hdf(f'{name}_{i+1}.h5', 'x', mode='w')\n",
    "    df.iloc[int((l/n)*(n-1)):l].to_hdf(f'{name}_{n}.h5', 'x', mode='w')\n",
    "    \n",
    "def readheavy(name, n, column, Dir):\n",
    "    result = pd.DataFrame(columns=column)\n",
    "    for i in range(n):\n",
    "        df = pd.read_hdf(f'Data/{Dir}/{name}_{i+1}.h5', 'x')\n",
    "        result = pd.concat([result, df], ignore_index=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfbfa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restore Datasets\n",
    "\n",
    "test = readheavy('test', 2, ['stft', 'y'], 'Spect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb72a525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test['stft'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ce61d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = readheavy('validation', 2, ['stft', 'y'], 'Spect')\n",
    "training = readheavy('training', 16, ['stft', 'y'], 'Spect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1c693f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1291"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.loc[1, 'stft'].transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdff50ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(df, n_samples):\n",
    "    df_clip = pd.DataFrame(columns=list(df.columns))\n",
    "    t = len(df[df.columns[0]][1][1])\n",
    "    for j in range(len(df)):\n",
    "        full = df.loc[j, df.columns[0]].transpose()\n",
    "        n=0\n",
    "        while (n<(len(full)-n_samples)):\n",
    "            clip = full[n: (n+n_samples)]\n",
    "            y = df.loc[j, 'y']\n",
    "            df_clip = df_clip.append({df.columns[0]: clip, 'y': y,}, ignore_index=True)\n",
    "            n+=int(n_samples/2)\n",
    "    return df_clip\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5734007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clip = clip(test, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05418643",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_clip = clip(validation, 128)\n",
    "training_clip = clip(training, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "912134f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121486,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_clip['stft'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0454bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Class for the creation of torch manageble datasets, with Format one can select the desired input column \n",
    "class DataAudio(Dataset):\n",
    "\n",
    "    def __init__(self, split, Format, transform=None):\n",
    "        self.x = split[Format]\n",
    "        self.y = split['y']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(32000, len(self.x))\n",
    "        #return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx, 0, 0].astype(float)\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "081acbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 513)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clip['stft'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c6997f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    ToTensor(), #this converts numpy or Pil image to torch tensor and normalizes it in 0, 1\n",
    "    RandomAffine((0.05, 0.05)),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomVerticalFlip()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76641069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of torch suited dataset classes  (change string 'mel' to select desired Format)\n",
    "training_dataset = DataAudio(training_clip, 'stft',transforms)\n",
    "validation_dataset = DataAudio(validation_clip, 'stft',transforms)\n",
    "test_dataset = DataAudio(test_clip, 'stft',transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad5d3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of dataloader classes\n",
    "batch_size = 64\n",
    "training_dataloader = DataLoader(training_dataset, batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34694094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
